{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9806fd2e-2a36-4f33-9ef2-bd7c5a6bcac4",
      "metadata": {
        "id": "9806fd2e-2a36-4f33-9ef2-bd7c5a6bcac4",
        "outputId": "999a35f2-7298-4420-da2c-486ef1d80590",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "%pip install python-dotenv --upgrade --quiet langchain langchain-huggingface sentence-transformers langchain-community\n",
        "%pip install -q langchain-google-genai\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import os\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Using a FREE, open-source model from Hugging Face\n",
        "# 'all-MiniLM-L6-v2' is small, fast, and very good for English.\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96a3be3e-93cf-4f75-a0da-74265c14e034",
      "metadata": {
        "id": "96a3be3e-93cf-4f75-a0da-74265c14e034",
        "outputId": "75a60fa9-ed4e-456f-cde0-1dad7a27a208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensionality: 384\n",
            "First 5 numbers: [-0.006138487718999386, 0.03101177327334881, 0.06479360908269882, 0.01094149798154831, 0.005267191678285599]\n"
          ]
        }
      ],
      "source": [
        "vector = embeddings.embed_query(\"Apple\")\n",
        "\n",
        "print(f\"Dimensionality: {len(vector)}\")\n",
        "print(f\"First 5 numbers: {vector[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b90d525-fa8b-4e45-be4c-2c6e9bf5b185",
      "metadata": {
        "id": "7b90d525-fa8b-4e45-be4c-2c6e9bf5b185",
        "outputId": "57867a27-d9b1-4f5a-cd7b-0f37cf208b2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rat vs Cat: 0.4981\n",
            "Cat vs Dog: 0.5067\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "vec_cat = embeddings.embed_query(\"Rat\")\n",
        "vec_dog = embeddings.embed_query(\"Cat\")\n",
        "vec_car = embeddings.embed_query(\"Dog\")\n",
        "\n",
        "print(f\"Rat vs Cat: {cosine_similarity(vec_cat, vec_dog):.4f}\")\n",
        "print(f\"Cat vs Dog: {cosine_similarity(vec_cat, vec_car):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a093d017-e684-4a6f-9d14-d4e088e410fb",
      "metadata": {
        "id": "a093d017-e684-4a6f-9d14-d4e088e410fb",
        "outputId": "d5bb4d8c-816b-4eed-8ced-3f5fa528dc55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "%pip install python-dotenv --upgrade --quiet faiss-cpu langchain-huggingface sentence-transformers langchain-community\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "\n",
        "# Using the same free model as Part 4a\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d26b41e6-5a63-4a9d-b495-f26d736dfd36",
      "metadata": {
        "id": "d26b41e6-5a63-4a9d-b495-f26d736dfd36"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "docs = [\n",
        "    Document(page_content=\"Reanna's favorite pet is Husky with heterochromia.\"),\n",
        "    Document(page_content=\"The secret password to the lab is 'Fuchsia'.\"),\n",
        "    Document(page_content=\"LangChain is a framework for developing applications powered by language models.\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf93509-cefe-432a-84cd-660934087672",
      "metadata": {
        "id": "2cf93509-cefe-432a-84cd-660934087672"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7c34223-0df3-4a38-a0f9-df4d979ad3a9",
      "metadata": {
        "id": "d7c34223-0df3-4a38-a0f9-df4d979ad3a9",
        "outputId": "acfcccf7-f978-4606-baae-48d810c37be8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The secret password to the lab is 'Fuchsia'.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template = \"\"\"\n",
        "Answer based ONLY on the context below:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "result = chain.invoke(\"What is the secret password?\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1bb35c4-7953-4ef0-8322-aefa7f2cbe34",
      "metadata": {
        "id": "a1bb35c4-7953-4ef0-8322-aefa7f2cbe34"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Mock Data: 10,000 vectors of size 128\n",
        "d = 128\n",
        "nb = 10000\n",
        "xb = np.random.random((nb, d)).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(xb)"
      ],
      "metadata": {
        "id": "xvuhgn906sYQ"
      },
      "id": "xvuhgn906sYQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "865cbf2e-2e2e-49e2-b245-58d515e650be",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "865cbf2e-2e2e-49e2-b245-58d515e650be",
        "outputId": "104283c2-7bf7-4f20-8d69-5f59f962aeb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9921946  0.25170207 0.42734024 0.90461874 0.44933793 0.7279866\n",
            " 0.71830857 0.39484948 0.6749314  0.27950346]\n"
          ]
        }
      ],
      "source": [
        "vector_0 = index.reconstruct(0)\n",
        "print(vector_0[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41236381-b84d-4709-86ad-74e2d4d24380",
      "metadata": {
        "id": "41236381-b84d-4709-86ad-74e2d4d24380",
        "outputId": "a84bdfaa-2c5b-4f8f-d791-648f93c53026",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flat Index contains 10000 vectors\n",
            "Nearest vector indices: [[8527 9805 9939 1951 7958]]\n",
            "Distances: [[13.92054  14.046453 14.464242 14.831488 14.842429]]\n"
          ]
        }
      ],
      "source": [
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(xb)\n",
        "print(f\"Flat Index contains {index.ntotal} vectors\")\n",
        "xq = np.random.random((1, d)).astype('float32')\n",
        "k = 5\n",
        "D, I = index.search(xq, k)\n",
        "\n",
        "print(\"Nearest vector indices:\", I)\n",
        "print(\"Distances:\", D)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2631179f-8f75-4fc4-8f4a-1a02906308c5",
      "metadata": {
        "id": "2631179f-8f75-4fc4-8f4a-1a02906308c5"
      },
      "outputs": [],
      "source": [
        "nlist = 100 # How many 'zip codes' (clusters) we want\n",
        "quantizer = faiss.IndexFlatL2(d) # The calculator for distance\n",
        "index_ivf = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
        "\n",
        "# We MUST train it first so it learns where the clusters are\n",
        "index_ivf.train(xb)\n",
        "index_ivf.add(xb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1eec4e0-b09f-43ed-9839-117f230b95ef",
      "metadata": {
        "id": "b1eec4e0-b09f-43ed-9839-117f230b95ef",
        "outputId": "6b60c641-8b99-490c-e8c7-c90cd4c50441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is index trained? True\n",
            "Total vectors in index: 10000\n",
            "Number of clusters (nlist): 100\n"
          ]
        }
      ],
      "source": [
        "print(\"Is index trained?\", index_ivf.is_trained)\n",
        "print(\"Total vectors in index:\", index_ivf.ntotal)\n",
        "print(\"Number of clusters (nlist):\", index_ivf.nlist)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc5245a-5e87-4ab5-a0b3-8724283c32e8",
      "metadata": {
        "scrolled": true,
        "id": "8dc5245a-5e87-4ab5-a0b3-8724283c32e8",
        "outputId": "f5cde11d-4737-4d84-a43c-814ccd7d3bf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nearest indices: [[6723 1377 8460 6466  991]]\n",
            "Distances: [[14.630767  15.6568985 15.716265  16.214739  16.348095 ]]\n"
          ]
        }
      ],
      "source": [
        "index_ivf.nprobe = 5   # search in 5 clusters\n",
        "\n",
        "xq = np.random.random((1, d)).astype('float32')\n",
        "D, I = index_ivf.search(xq, 5)\n",
        "\n",
        "print(\"Nearest indices:\", I)\n",
        "print(\"Distances:\", D)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "953a28a2-6144-4547-b456-4706183ae6ff",
      "metadata": {
        "id": "953a28a2-6144-4547-b456-4706183ae6ff",
        "outputId": "0dd9426d-f1e2-49bb-b68e-12edb2e2e5e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nearest indices: [[5810 4498 5017 8527 5388]]\n",
            "Distances: [[13.2250805 14.18395   14.899651  14.925881  14.96047  ]]\n"
          ]
        }
      ],
      "source": [
        "index_ivf.nprobe = 5   # search in 5 clusters\n",
        "\n",
        "xq = np.random.random((1, d)).astype('float32')\n",
        "D, I = index_ivf.search(xq, 5)\n",
        "\n",
        "print(\"Nearest indices:\", I)\n",
        "print(\"Distances:\", D)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3562d51c-b4c2-4efb-a8fb-0853ebf40b11",
      "metadata": {
        "id": "3562d51c-b4c2-4efb-a8fb-0853ebf40b11"
      },
      "outputs": [],
      "source": [
        "M = 16 # Number of connections per node (The 'Hub' factor)\n",
        "index_hnsw = faiss.IndexHNSWFlat(d, M)\n",
        "index_hnsw.add(xb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82edff39-c9cd-4354-8e65-ffd7b64865ff",
      "metadata": {
        "id": "82edff39-c9cd-4354-8e65-ffd7b64865ff",
        "outputId": "10f85c76-f027-4b31-daf7-6007e7d5bcba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nearest indices: [[8343 7021 6946 5123 5488]]\n",
            "Distances: [[11.865313  12.793842  13.438298  13.82095   13.9195595]]\n"
          ]
        }
      ],
      "source": [
        "xq = np.random.random((1, d)).astype('float32')\n",
        "\n",
        "D, I = index_hnsw.search(xq, 5)\n",
        "\n",
        "print(\"Nearest indices:\", I)\n",
        "print(\"Distances:\", D)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f4554c2-ff1c-4842-8e52-65479daa9b9a",
      "metadata": {
        "id": "0f4554c2-ff1c-4842-8e52-65479daa9b9a",
        "outputId": "b8661fa2-87f5-4379-d65a-c4a67fc30b25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PQ Compression complete. RAM usage minimized.\n"
          ]
        }
      ],
      "source": [
        "m = 8 # Split vector into 8 sub-vectors\n",
        "index_pq = faiss.IndexPQ(d, m, 8)\n",
        "index_pq.train(xb)\n",
        "index_pq.add(xb)\n",
        "print(\"PQ Compression complete. RAM usage minimized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "841d31b6-59be-4bf0-87a6-9d293ea0a13d",
      "metadata": {
        "id": "841d31b6-59be-4bf0-87a6-9d293ea0a13d"
      },
      "source": [
        "| Index | Speed     | Accuracy  | Memory   |\n",
        "| ----- | --------- | --------- | -------- |\n",
        "| Flat  | Slow      | 100%      | High     |\n",
        "| IVF   | Fast      | High      | Medium   |\n",
        "| HNSW  | Very Fast | Very High | High     |\n",
        "| PQ    | Very Fast | Medium    | Very Low |\n",
        "\n",
        "| Method | Think as        |\n",
        "| ------ | --------------- |\n",
        "| Flat   | Check All       |\n",
        "| IVF    | Go to Section   |\n",
        "| HNSW   | Travel via Hubs |\n",
        "| PQ     | Compress Data   |\n",
        "\n",
        "Flat → Exact but heavy\n",
        "IVF → Clustered search\n",
        "HNSW → Graph navigation\n",
        "PQ → Compressed storage\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}