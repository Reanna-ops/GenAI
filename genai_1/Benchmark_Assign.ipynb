{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2704d6ec-eaf6-44bb-996f-34e9487ca2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: torch in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.25.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\reanna netto\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.3.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\reanna netto\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2026.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (12.1.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (6.33.4)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\reanna netto\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (25.12.19)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: rich in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.3.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\reanna netto\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer-slim->transformers) (8.3.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\reanna netto\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\reanna netto\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\reanna netto\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Reanna Netto\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch torchvision torchaudio tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18df1e4e-9a84-49de-a664-f19cf30b47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e0d4006-55e8-4921-a937-6a5c511b0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a6563bd-05b2-4867-8a66-e837e4662897",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\Reanna Netto\\unit 1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16a4d8c7-867f-4ee9-a796-f4763bce1ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    print(\"File loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{file_path}' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a8349-97ba-4d2a-ab4e-2475cebd7d24",
   "metadata": {},
   "source": [
    "# Experiment 1: Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "210f1c90-fbb8-413b-83e5-8046df6bd1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e9cbaea-d21c-4300-9338-9c5c8d8e926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The future of AI is\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3852b8-c51b-409b-99a2-d15661d699e9",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43f867e8-1c55-42f9-8094-3661618a8ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Loading weights: 100%|██████████| 202/202 [00:00<00:00, 227.25it/s, Materializing param=cls.predictions.transform.dense.weight]                 \n",
      "BertLMHeadModel LOAD REPORT from: bert-base-uncased\n",
      "Key                         | Status     |  | \n",
      "----------------------------+------------+--+-\n",
      "bert.pooler.dense.weight    | UNEXPECTED |  | \n",
      "cls.seq_relationship.weight | UNEXPECTED |  | \n",
      "cls.seq_relationship.bias   | UNEXPECTED |  | \n",
      "bert.pooler.dense.bias      | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=25) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The future of AI is. as housing to \" \" \" \" \" \" ( ) ( \" (, - ( ) ( \" \" \". it out all there way way on being so jefferson long beth for \" ( ( \" ( ( )ach, \" ( ( \". but and and - - - - ( as more actually so \" \". of the and and and and \". it more actually, - - ( ) ( \". are and and - ( ( \". it but who the to is'] \" ( ) in \". it that as that many so so jefferson is'\" ( \" ( \" ( \" ( ( ( ) ) (, that those being \" \" \" ( ( -, that those being that as that it out all shit to \". and and - - - ( \" \".. which they with is and \" ( \". it this and and \" and and \". '!!!!!! j (. an a a the were me to himxt in most em it that a ( ) ) ) ( as and in it it many so the the the do who now will so law them often often \" siroch - \" ( / the rest with success storm with first a and.,ne general like government general is '\n"
     ]
    }
   ],
   "source": [
    "fast_generator = pipeline('text-generation', model=\"bert-base-uncased\")\n",
    "output_fast = fast_generator(prompt, max_length=25, num_return_sequences=1)\n",
    "print(output_fast[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33d7f8-7253-42a0-8d86-596d0f2a4ee0",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a2aa7f9-59cd-41eb-8931-68dc469f9166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Loading weights: 100%|██████████| 202/202 [00:01<00:00, 194.88it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "RobertaForCausalLM LOAD REPORT from: roberta-base\n",
      "Key                             | Status     |  | \n",
      "--------------------------------+------------+--+-\n",
      "roberta.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=25) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The future of AI is\n"
     ]
    }
   ],
   "source": [
    "fast_generator = pipeline('text-generation', model=\"roberta-base\")\n",
    "output_fast = fast_generator(prompt, max_length=25, num_return_sequences=1)\n",
    "print(output_fast[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447eeafe-65b3-4490-b5e2-4eb1863aa2e1",
   "metadata": {},
   "source": [
    "### BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fa4440e-f2cb-4949-ac62-116c22f83b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 159/159 [00:00<00:00, 239.64it/s, Materializing param=model.decoder.layers.5.self_attn_layer_norm.weight]   \n",
      "This checkpoint seem corrupted. The tied weights mapping for this model specifies to tie model.decoder.embed_tokens.weight to lm_head.weight, but both are absent from the checkpoint, and we could not find another related tied weight for those keys\n",
      "BartForCausalLM LOAD REPORT from: facebook/bart-base\n",
      "Key                                                           | Status     | \n",
      "--------------------------------------------------------------+------------+-\n",
      "encoder.layernorm_embedding.bias                              | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.self_attn_layer_norm.weight | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.final_layer_norm.bias       | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.fc1.weight                  | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.fc1.bias                    | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.self_attn.q_proj.weight     | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.final_layer_norm.weight     | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.self_attn.v_proj.bias       | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.self_attn_layer_norm.bias   | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.self_attn.v_proj.weight     | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.fc2.bias                    | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.self_attn.out_proj.bias     | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.self_attn.k_proj.weight     | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.self_attn.out_proj.weight   | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.self_attn.k_proj.bias       | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.self_attn.q_proj.bias       | UNEXPECTED | \n",
      "encoder.layers.{0, 1, 2, 3, 4, 5}.fc2.weight                  | UNEXPECTED | \n",
      "shared.weight                                                 | UNEXPECTED | \n",
      "encoder.embed_positions.weight                                | UNEXPECTED | \n",
      "encoder.layernorm_embedding.weight                            | UNEXPECTED | \n",
      "lm_head.weight                                                | MISSING    | \n",
      "model.decoder.embed_tokens.weight                             | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=25) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The future of AI is greetingsuff nanotimeout Laur Airl上上gling defer defer上上 nicerSay nicer Vest Vest_(til Vest prize Vest_( Tenn Di prize defer answersPalest mediocre Boyd defer deferstudentstudentstudent JihadTipoggle orientationstudentTip上 departing Laurcon mediocre defer_(_(_(.) nicerometerometer Jihad�Palest 380 orientation Jihadogglestudentoggle residentsstudentstudentoggleogglestudent orientationmansoggleoggleoggleometeroggle orientation orientation orientationStarting Laur Laur Psychological Laur Laur RIGHT RIGHTиometer.)oggleoggle nicer Psychological Wor deferogglestudent391oggle prizestudentoggle nightmaresoggleoggle prizeoggleoggle CTRometerPalestoggleиoggleoggle Worgling orientation orientationoggleometer.) departingoggleshapeshifteroggleoggle bedsoggleoggle haz.) orientation orientation�oggleoggle Heb orientation haz PsychologicalogglePalest orientation Jihad Heboggleshapeshifter PsychologicalTipUntitledoggleogglethatoggleogglePalestoggleoggle residents391oggle Heb上Palestoggle residentsoggleoggleshapeshifterthat Carsonoggle Lauronoggle Laur orientationoggle RIGHToggleshapeshifter Woroggle RIGHT RIGHT departingoggle orientationoggle orientation departingoggleoggle departing orientationogglethat Gumshapeshifter WorPalest feedingoggleshapeshifter LauroggleistsOs RIGHT Heb Heboggleoggle Lauristsoggleists departingPalestoggle Carsonstudentonometeroggle hazoggle JihadoggleoggleOsoggle Heboggle shatteroggle Laur Wor departingonoggleoggle handsetoggle Heb Heb MPHoggleoggle Carsonoggle\n"
     ]
    }
   ],
   "source": [
    "fast_generator = pipeline('text-generation', model=\"facebook/bart-base\")\n",
    "output_fast = fast_generator(prompt, max_length=25, num_return_sequences=1)\n",
    "print(output_fast[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10356483-ff90-428a-9965-12243be54f64",
   "metadata": {},
   "source": [
    "# Experiment 2: Masked Language Modeling (Missing Word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56827c24-1d11-4796-a6a5-cf685c9bdd84",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9095c512-7299-4a46-8842-b14c4f1337e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 202/202 [00:00<00:00, 237.37it/s, Materializing param=cls.predictions.transform.dense.weight]                 \n",
      "BertForMaskedLM LOAD REPORT from: bert-base-uncased\n",
      "Key                         | Status     |  | \n",
      "----------------------------+------------+--+-\n",
      "bert.pooler.dense.weight    | UNEXPECTED |  | \n",
      "cls.seq_relationship.weight | UNEXPECTED |  | \n",
      "cls.seq_relationship.bias   | UNEXPECTED |  | \n",
      "bert.pooler.dense.bias      | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "mask_filler = pipeline(\"fill-mask\", model=\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cd94a18-abce-448c-8509-7625ec3553ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create: 0.54\n",
      "generate: 0.16\n",
      "produce: 0.05\n",
      "develop: 0.04\n",
      "add: 0.02\n"
     ]
    }
   ],
   "source": [
    "masked_sentence = \"The goal of Generative AI is to [MASK] new content.\"\n",
    "preds = mask_filler(masked_sentence)\n",
    "\n",
    "for p in preds:\n",
    "    print(f\"{p['token_str']}: {p['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e726ed-e41b-48a3-9f4c-a3c4a2db493d",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd516a08-5e8f-4552-ae14-8642d0f5fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 202/202 [00:00<00:00, 203.87it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "RobertaForMaskedLM LOAD REPORT from: roberta-base\n",
      "Key                             | Status     |  | \n",
      "--------------------------------+------------+--+-\n",
      "roberta.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "mask_filler = pipeline(\"fill-mask\", model=\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97b367ba-b1a8-4460-a582-92e13b3ab4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " generate: 0.37\n",
      " create: 0.37\n",
      " discover: 0.08\n",
      " find: 0.02\n",
      " provide: 0.02\n"
     ]
    }
   ],
   "source": [
    "masked_sentence = \"The goal of Generative AI is to <mask> new content.\"\n",
    "preds = mask_filler(masked_sentence)\n",
    "\n",
    "for p in preds:\n",
    "    print(f\"{p['token_str']}: {p['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd70cf8-6de3-4fc2-8e22-35c597bb15a2",
   "metadata": {},
   "source": [
    "### BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ddadac5-982e-4fb2-80d2-0e8391b37a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 259/259 [00:01<00:00, 227.71it/s, Materializing param=model.shared.weight]                                  \n"
     ]
    }
   ],
   "source": [
    "mask_filler = pipeline(\"fill-mask\", model=\"facebook/bart-base\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f20ac579-75ab-48c2-8cae-0c95ca85ab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " create: 0.07\n",
      " help: 0.07\n",
      " provide: 0.06\n",
      " enable: 0.04\n",
      " improve: 0.03\n"
     ]
    }
   ],
   "source": [
    "masked_sentence = \"The goal of Generative AI is to <mask> new content.\"\n",
    "preds = mask_filler(masked_sentence)\n",
    "\n",
    "for p in preds:\n",
    "    print(f\"{p['token_str']}: {p['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a86ac13-3359-4647-8594-7ef2c7bc7ce5",
   "metadata": {},
   "source": [
    "# Experiment 3: Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5773b2d-d76c-4a17-a805-2414f887c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the risks?\"\n",
    "context = \"Generative AI poses significant risks such as hallucinations, bias, and deepfakes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5258a79-74f5-4c9d-91f7-8d1efcf8ab94",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63d50431-ab8d-4ce9-b416-e7e3c2f72f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 221.60it/s, Materializing param=bert.encoder.layer.11.output.dense.weight]              \n",
      "BertForQuestionAnswering LOAD REPORT from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "bert.pooler.dense.weight                   | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "bert.pooler.dense.bias                     | UNEXPECTED | \n",
      "qa_outputs.bias                            | MISSING    | \n",
      "qa_outputs.weight                          | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    }
   ],
   "source": [
    "qa_pipeline = pipeline(\"question-answering\", model=\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7687d97f-62e4-4eb2-b6ec-ade0fe471584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are the risks?\n",
      "A: , and deepfakes\n"
     ]
    }
   ],
   "source": [
    "res = qa_pipeline(question=question, context=context)\n",
    "print(f\"Q: {question}\")\n",
    "print(f\"A: {res['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abec252-5008-42f1-92cf-baaa7508816e",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb7c3a12-f5a9-4e05-b6e8-05810667e7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 210.95it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "RobertaForQuestionAnswering LOAD REPORT from: roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "qa_outputs.bias                 | MISSING    | \n",
      "qa_outputs.weight               | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    }
   ],
   "source": [
    "qa_pipeline = pipeline(\"question-answering\", model=\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e4fea24-833d-48fa-8c67-ee0e13fea0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are the risks?\n",
      "A: Generative AI poses significant risks such\n"
     ]
    }
   ],
   "source": [
    "res = qa_pipeline(question=question, context=context)\n",
    "print(f\"Q: {question}\")\n",
    "print(f\"A: {res['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b69d2-4c15-4695-b5eb-6e90221e2258",
   "metadata": {},
   "source": [
    "### BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce222d90-043c-40ab-a73a-3d8485a84180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 259/259 [00:00<00:00, 300.73it/s, Materializing param=model.shared.weight]                                  \n",
      "BartForQuestionAnswering LOAD REPORT from: facebook/bart-base\n",
      "Key               | Status  | \n",
      "------------------+---------+-\n",
      "qa_outputs.bias   | MISSING | \n",
      "qa_outputs.weight | MISSING | \n",
      "\n",
      "Notes:\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    }
   ],
   "source": [
    "qa_pipeline = pipeline(\"question-answering\", model=\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37119e95-a845-4517-9728-d38f0ebd3e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are the risks?\n",
      "A: , and deepfakes\n"
     ]
    }
   ],
   "source": [
    "res = qa_pipeline(question=question, context=context)\n",
    "print(f\"Q: {question}\")\n",
    "print(f\"A: {res['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba83165-cb63-4b17-a900-f3b76cf54b0d",
   "metadata": {},
   "source": [
    "# Observation Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8f1d6-4f94-4875-a0e4-4fe2b7262078",
   "metadata": {},
   "source": [
    "| Task | Model | Classification (Success/Failure) | Observation (What actually happened?) | Why did this happen? (Architectural Reason) |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Generation** | BERT | *Failure* | *Generated highly incoherent text with repeated punctuation, symbols, and random fragments instead of meaningful sentences.* | *BERT is an encoder-only model trained with Masked Language Modeling and is not designed for next-token (causal) prediction.* |\n",
    "|  | RoBERTa | *Failure* | *Returned only the input prompt “The future of AI is” without any continuation.* | *RoBERTa is also encoder-only and cannot autoregressively generate new tokens.* |\n",
    "|  | BART | *Failure* | *Produced extremely long, noisy, and random-looking text containing meaningless words, symbols, and mixed-language fragments.* | *BART is an encoder–decoder model, but the text-generation pipeline expects a decoder-only causal language model, causing architectural misuse.* |\n",
    "| **Fill-Mask** | BERT | *Success* | *Predicted create (0.54), generate (0.16), produce (0.05).* | *BERT is explicitly trained for Masked Language Modeling (MLM), making it effective at predicting missing tokens.* |\n",
    "|  | RoBERTa | *Success* | *Predicted generate (0.37), create (0.37), discover (0.08).* | *RoBERTa is trained using MLM with improved optimization and larger pretraining data than BERT.* |\n",
    "|  | BART | *Partial Success* | *Predicted more generic words like create (0.07), help (0.07), provide (0.06).* | *BART is trained using denoising autoencoding and is not optimized for single-token mask prediction.* |\n",
    "| **QA** | BERT | *Partial Success* | *Returned incomplete answer fragment: “, and deepfakes”.* | *Base BERT is not fine-tuned for extractive Question Answering, leading to weak span prediction.* |\n",
    "|  | RoBERTa | *Partial Success* | *Returned truncated answer: “Generative AI poses significant risks such”.* | *Although RoBERTa has strong representations, lack of QA fine-tuning causes incomplete answer spans.* |\n",
    "|  | BART | *Failure* | *Failed to return a clear or complete answer due to missing QA head parameters.* | *BART-base is primarily designed for sequence-to-sequence generation and requires explicit fine-tuning for extractive QA tasks.* |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
